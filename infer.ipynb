{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe28b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load all desired packages\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import h5py\n",
    "\n",
    "\n",
    "import os, sys\n",
    "directory = os.path.abspath('')\n",
    "sys.path.insert(1,os.path.join(directory,'src')) # setting path can also append directory.parent\n",
    "#import utils\n",
    "#import metrics\n",
    "import datasets\n",
    "import evaluate\n",
    "#import plots\n",
    "#import train\n",
    "#from UNet import UNet\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#--------- DEFINE FUNCTIONS HERE ------------\n",
    "#Dataloader that opens up the int2 files and returns them with dimensions (256 x 256 x number of slices)\n",
    "def open_int2(path_,dim_x=256, dim_y=256):\n",
    "    img_raw = np.fromfile(path_, dtype='>i2')\n",
    "    _img = img_raw.reshape((dim_x,dim_y,-1),order='F')\n",
    "    _img = np.rot90(_img, axes=(1,0))\n",
    "    _img = np.flip(_img, axis=1)\n",
    "    return _img\n",
    "\n",
    "def load_result(filename:str, key:str, data_type=np.float64):\n",
    "    f = h5py.File(filename, 'r')\n",
    "    data = f[key][()].astype(data_type)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "# We need to infer on 256x256 images, here we reshape into the original dims\n",
    "def resize_imgs(pred,dim_x=512,dim_y=512):\n",
    "    _img = np.rot90(pred, axes=(1,0))\n",
    "    _img = np.flip(_img, axis=1)\n",
    "    _img = _img.reshape((dim_x,dim_y,-1),order='F') \n",
    "    _img = np.rot90(_img, axes=(1,0))\n",
    "    _img = np.flip(_img, axis=1)\n",
    "    return _img\n",
    "\n",
    "def plot_QC(img_list:list,idx=12,clim:list=None,cmap:str='jet'):\n",
    "    plt.figure(figsize = (10,6))\n",
    "    counter = 1\n",
    "    for img_path in img_list:\n",
    "        if os.path.splitext(img_path)[1]=='.h5':\n",
    "            img = load_result(img_path,'pred')\n",
    "        elif os.path.splitext(img_path)[1]=='.int2': \n",
    "            img = open_int2(img_path).astype(np.float64)\n",
    "        \n",
    "        #QC plot\n",
    "        plt.subplot(2,3,counter)\n",
    "        if clim==None:\n",
    "            plt.imshow(img[:,:,idx],cmap=cmap) \n",
    "        else:\n",
    "            plt.imshow(img[:,:,idx],clim=clim,cmap=cmap) \n",
    "        patient = (img_path.replace('/data/path/','')).split('/')[0]\n",
    "        plt.title(f'{patient} slice {idx}')\n",
    "\n",
    "        counter = counter+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab6378d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef87259-a394-49f2-9eee-acd5ec419b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "#set training and validation batch sizes, other training parameters, and path to labels\n",
    "\n",
    "# If you would like to refer to the best model from training use ref_num 1031\n",
    "#model_info_file= '/data/knee_mri9/mwtong/t1rho_map_synthesis/training/trained_model_info.csv'\n",
    "#Load the csv with all your trained models\n",
    "#df_modelInfo = pd.read_csv(model_info_file)\n",
    "#ref_num = 1031\n",
    "#row_idx = np.where(df_modelInfo['Ref']==float(ref_num))[0][0]\n",
    "#df_best = df_modelInfo.iloc[row_idx]\n",
    "\n",
    "\n",
    "model_path = '/data/knee_mri9/mwtong/t1rho_map_synthesis/code/code_py/checkpoints/run_604_best_model'\n",
    "scaleInput_options  = ['clip', 0, 150]\n",
    "\n",
    "print(model_path)\n",
    "print(scaleInput_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfe9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "#list of paths to the data\n",
    "data_path = '/data/folder'\n",
    "t2_paths = glob.glob(f'{data_path}/*/*/reg/T2_Map.int2')\n",
    "\n",
    "t1r_paths = [x.replace('/T2','/T1rho') for x in t2_paths]\n",
    "syn_t1r_paths = [x.replace('T1rho_Map.int2','Syn_T1rho_Map.h5') for x in t1r_paths]\n",
    "e1_paths = [x.replace('T1rho_Map.int2','Echo_e1.int2') for x in t1r_paths]\n",
    "\n",
    "fig = plot_QC(e1_paths,cmap='gray')\n",
    "\n",
    "fig = plot_QC(t2_paths,clim=[0,80],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d35c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af5f41-1b65-43c4-81c7-6292eb647a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2681c89e-136e-43bd-b58c-7999341cbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the path to the image and slice number\n",
    "t2_path_by_slices_list = []\n",
    "slice_nums_list = []\n",
    "for t2_path in t2_paths:\n",
    "    t2_map = open_int2(t2_path).astype(np.float64)\n",
    "    n_slices = np.shape(t2_map)[2]\n",
    "    \n",
    "    t2_path_by_slices_list.extend([t2_path] * n_slices)\n",
    "    slice_nums_list.extend(np.arange(0,n_slices))\n",
    "    \n",
    "    print(t2_path, n_slices)\n",
    "\n",
    "df_infer = pd.DataFrame()\n",
    "df_infer['t2'] = t2_path_by_slices_list\n",
    "df_infer['slice number'] = slice_nums_list\n",
    "df_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7249e-9c37-4854-b0ab-54740dae5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Inference\n",
    "preds,images,inferset = evaluate.get_model_infers(df_infer,model_path,scaleInput_options)\n",
    "\n",
    "print(len(df_infer))\n",
    "print(np.shape(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd747e2-f4b9-47e0-9644-fc18959b8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "for ii in range(len(t2_paths)):\n",
    "    t2_path = t2_paths[ii]\n",
    "    syn_t1r_path = syn_t1r_paths[ii]\n",
    "    vol_indices = list(np.where(df_infer['t2']==t2_path))\n",
    "\n",
    "    pred_vol = np.squeeze(preds[vol_indices,0,:,:].numpy())\n",
    "    pred_vol = np.transpose(pred_vol,[1,2,0])\n",
    "    print(syn_t1r_path, np.shape(pred_vol))\n",
    "\n",
    "    with h5py.File(syn_t1r_path, 'w') as f:\n",
    "        dset = f.create_dataset('pred', data=pred_vol, dtype=pred_vol.dtype)\n",
    "syn_t1r_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad38b79-a008-4f57-b9b8-0b9d5e2f44a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27576e68-7e07-441e-9e09-67e40a5410bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for QC\n",
    "#Ground Truth\n",
    "plot_QC(t1r_paths,idx=6,clim=[0,80],cmap='jet')\n",
    "#Preds\n",
    "plot_QC(syn_t1r_paths,idx=6,clim=[0,80],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb6cb2-9e12-4a3b-b244-440dcc289c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af786f3-9e4c-4a22-a2c6-18e51bb7aebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de760356-07b3-42b6-ae34-b3b5cdc9478b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b7b497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_t1rsyn",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

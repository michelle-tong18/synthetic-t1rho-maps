{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d994a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all desired packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "from math import exp\n",
    "\n",
    "import torch\n",
    "\n",
    "#MT additions\n",
    "from torchvision import datasets, transforms\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "\n",
    "import os, sys\n",
    "directory = os.path.abspath('')\n",
    "sys.path.insert(1,os.path.join(directory,'src')) # setting path can also append directory.parent\n",
    "import utils\n",
    "import metrics\n",
    "import datasets\n",
    "import plots\n",
    "import train\n",
    "from UNet import UNet\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b98947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this code on GPU if you can (much faster), otherwise run on CPU\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda\"\n",
    "    device = torch.device(dev)\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "    device = torch.device(dev)\n",
    "\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set training parameters and paths to save directories, logging directories, your split, etc.\n",
    "batch_size     = 1\n",
    "val_batch_size = 1\n",
    "\n",
    "num_workers    = 1\n",
    "\n",
    "num_it         = 1\n",
    "modifications  = ''\n",
    "\n",
    "maxDisp = 150\n",
    "\n",
    "\n",
    "proj_path      = '/data/knee_mri9/mwtong/t1rho_map_synthesis'\n",
    "#this is where you'll save log files of your training\n",
    "log_save_dir   = proj_path+'/training/train_logs/'\n",
    "#this is where you'll save the models themselves\n",
    "model_save_dir = proj_path+'/training/checkpoints/'\n",
    "#this is a csv that tracks training parameters and has paths to the specific log file and model checkpoints of \n",
    "#each run\n",
    "model_info_file= proj_path+'/training/trained_model_info.csv'\n",
    "\n",
    "split_path          = proj_path + '/splits/022_25to75Percent_Slices_NoKneeCoil.csv'\n",
    "num_epochs          = 2\n",
    "lr                  = 0.001\n",
    "scheduler_options   = ['constant',4]\n",
    "loss_options        = ['12','NRMSE',0.6,0.4]\n",
    "scaleInput_options  = ['clip',0,150]\n",
    "scaleMetrics_options= ['clip',0,100]\n",
    "do_augmentation     = False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29453ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467801c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load splits\n",
    "label_df = pd.read_csv(split_path)\n",
    "\n",
    "print(label_df['set'].value_counts())\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94766885",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126f949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine whether to augment data\n",
    "if do_augmentation == True:\n",
    "    #@title **Exercise:** Data augmentation\n",
    "    # Visit https://pytorch.org/vision/stable/transforms.html and search for the term 'Random'.\n",
    "    # This will give you a list of built-in functions for image augmentation.\n",
    "    # Choose and implement a few that you think are appropriate to diversify your dataset.\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.RandomRotation(8, fill=0.5),\n",
    "                    transforms.RandomAffine(degrees=0,translate=(0.1, 0.1),fill=0.5),\n",
    "                    transforms.RandomResizedCrop(size=256,scale=(0.96, 1.0),ratio=(1, 1)),\n",
    "     #               transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "                    transforms.Grayscale(num_output_channels=1),\n",
    "                    transforms.ConvertImageDtype(torch.float)\n",
    "                    ])\n",
    "\n",
    "    transform_type = transform\n",
    "else:\n",
    "    transform_type = None\n",
    "\n",
    "# load the training, validation, and test sets using the dataloader\n",
    "trainset = datasets.T1RT2Data(labels_df=label_df, set_name='train', transforms=transform_type,scale_options=['clipAndScale',0,150])\n",
    "valset   = datasets.T1RT2Data(labels_df=label_df, set_name='val')\n",
    "testset  = datasets.T1RT2Data(labels_df=label_df, set_name='test')\n",
    "print(trainset.len, valset.len, testset.len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize random entry from the training set\n",
    "ind   = random.randint(0,trainset.len-1)\n",
    "ind = 277\n",
    "print(ind)\n",
    "start = time.time()\n",
    "image,label = trainset.__getitem__(ind)\n",
    "end   = time.time()\n",
    "print('Image loading time: '+str(np.round(end-start,3))+' seconds')\n",
    "plots.plot_dataloader(trainset,ind,maxDisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3556dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf57a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d25f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File that we will eventually create to store training logs\n",
    "log_save   = os.path.join(log_save_dir,'run_'+str(len(os.listdir(log_save_dir))+1)+'.txt')\n",
    "#File path to which we will store the trained model\n",
    "model_save = os.path.join(model_save_dir,'run_'+str(len(os.listdir(log_save_dir))+1))\n",
    "print(log_save)\n",
    "print(model_save)\n",
    "\n",
    "#Load CNN of choice and assign to correct device\n",
    "generator_model = UNet(init_features = 64, in_channels = 1, out_channels = 1)\n",
    "if dev == \"cuda\":\n",
    "    generator_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALWAYS set random seeds when you train so that your training is reproducible!\n",
    "random.seed(14)\n",
    "torch.manual_seed(14)\n",
    "    \n",
    "# load the training, validation, and test sets using the dataloader\n",
    "trainset = datasets.T1RT2Data(labels_df=label_df, set_name='train')\n",
    "valset   = datasets.T1RT2Data(labels_df=label_df, set_name='val')\n",
    "testset  = datasets.T1RT2Data(labels_df=label_df, set_name='test')\n",
    "print(trainset.len, valset.len, testset.len)\n",
    "\n",
    "trainset_loader = datasets.DataLoader(trainset, batch_size=batch_size,shuffle=True,num_workers=num_workers,\n",
    "                             drop_last=True)\n",
    "valset_loader   = datasets.DataLoader(valset, batch_size=val_batch_size,shuffle=False,num_workers=num_workers,\n",
    "                             drop_last=False)\n",
    "testset_loader  = datasets.DataLoader(testset, batch_size=val_batch_size,shuffle=False,num_workers=num_workers,\n",
    "                             drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d55aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "#Load your loss function, optimizer, and learning rate scheduler, then set up and start training\n",
    "if scheduler_options[0]=='constant' and len(scheduler_options)==3:\n",
    "    gamma_=scheduler_options[2]\n",
    "else:\n",
    "    gamma_=0.1\n",
    "criterion = train.NetLoss()\n",
    "optimizer = torch.optim.Adam(generator_model.parameters(), lr=lr, weight_decay = 0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_options[1], gamma=gamma_)\n",
    "\n",
    "dataloaders = {'train': trainset_loader, 'val': valset_loader}\n",
    "generator_model, losses = train.train_model(dataloaders, generator_model, criterion, optimizer, scheduler, log_save,\n",
    "                            loss_options, scaleMetrics_options, scheduler_options, num_epochs, return_stats=True)\n",
    "\n",
    "#Save your model, and update the csv with the trained model list to reflect the parameters of this train, and paths \n",
    "#to best models.\n",
    "torch.save(generator_model, model_save)\n",
    "d = {'Ref':ii,'Model_Path': model_save, 'Log_Path': log_save,'Split_Path':split_path,\n",
    "         'epochs': [num_epochs], 'lr': [lr], 'scheduler:type,step,%lossChange,%lrDecrease':[scheduler_options],\n",
    "         'loss:type,metric,wSeg,wNotSeg': [loss_options],'scaleInputs:method,min,max':[scaleInput_options],\n",
    "         'scaleMetrics:method,min,max':[scaleMetrics_options],'augment':do_augmentation,'modifications': modifications,\n",
    "         'NRMSE': '','NRMSE_seg': '','best_loss': '','observations': ''}\n",
    "df = pd.DataFrame(data = d)\n",
    "\n",
    "df_full = pd.read_csv(model_info_file)\n",
    "df_full = df_full.append(df,ignore_index = True)\n",
    "#df_full.to_csv(model_info_file,index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53197f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b806bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load predictions for your trained model\n",
    "preds, labels = eval.test_metrics(valset_loader, generator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8fa7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize your predictions and corresponding ground truth\n",
    "ind       = random.randint(0,preds.shape[0]-1)\n",
    "\n",
    "fig  = plt.figure(figsize = (12,5))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.subplot(121)\n",
    "im1 = plt.imshow(preds[ind,0,:,:].cpu().detach().numpy(),cmap = 'jet')\n",
    "plt.clim([0,max_map])\n",
    "plt.axis('off')\n",
    "plt.title('Predicted T1rho Map')\n",
    "\n",
    "plt.subplot(122)\n",
    "im2 = plt.imshow(labels[ind,0,:,:].cpu().detach().numpy(),cmap = 'jet')\n",
    "plt.clim([0,max_map])\n",
    "plt.axis('off')\n",
    "plt.title('Ground Truth T1rho Map')\n",
    "\n",
    "fig.subplots_adjust(right=0.82)\n",
    "cbar_ax = fig.add_axes([0.85, 0.128, 0.01, 0.75])\n",
    "cbar = fig.colorbar(im2, cax=cbar_ax)\n",
    "cbar.set_label('T2 relaxation time (ms)',rotation = 270,labelpad = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afca7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e842f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee241e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d07c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f05eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
